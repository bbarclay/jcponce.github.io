<!doctype html>
<html lang="en">

<head>
	<meta charset="utf-8">

	<title>MATH2001/7000 - Chapter 11</title>

	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<link rel="stylesheet" href="dist/reveal.css">
	<link rel="stylesheet" href="dist/theme/white.css" id="theme">
	<link rel="stylesheet" href="plugin/chalkboard/style.css">
	<link rel="stylesheet" href="plugin/customcontrols/style.css">

	<link rel="stylesheet" href="css/mylayout.css" />

	<!-- Code syntax highlighting https://revealjs.com/-->
	<link rel="stylesheet" href="plugin/highlight/zenburn.css">

	<!-- Font awesome -->
	<link rel="stylesheet" href="css/fontawesome.css">

	<link rel="icon" type="image/png" href="images/icon/infinity32.png" sizes="32x32">
	<link rel="icon" type="image/png" href="images/icon/infinity16.png" sizes="16x16">

	<!-- Printing and PDF exports -->
	<script>
		var link = document.createElement('link');
		link.rel = 'stylesheet';
		link.type = 'text/css';
		link.href = window.location.search.match(/print-pdf/gi) ? 'export/pdf.css' :
			'export/paper.css';
		document.getElementsByTagName('head')[0].appendChild(link);
	</script>


	<!-- This script is to display Github buttons -->
	<script async defer src="js/buttons.js"></script>

	<!--[if lt IE 9]>
		<script src="../reveal.js/lib/js/html5shiv.js"></script>
		<![endif]-->

	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-JPYTNF6MB4"></script>
	<script src="js/google-analytics-ga4.js"></script>


</head>

<body>
	<div class="reveal">
		<div class="slides">

			<!-- Any section element inside of this container is displayed as a slide -->

			<section>
				<h2>Calculus & <br />Linear Algebra II</h2>
				<p>Chapter 11</p>
			</section>

			<section>
				<h3>11 Gram-Schmidt process</h3>
				<div class="left-txt size-80">
					<br />
					<p>
						The goal of this section is to discuss orthogonal
						projections, and develop a way of
						constructing an orthonormal basis for an inner
						product space.

					</p>

				</div>
				<br /><br /><br /><br /><br />

			</section>


			<section>

				<section data-auto-animate>
					<h4>11.1 Orthogonal set</h4>
					<div class="size-70">
						<div class="left-txt">
							<p>
								<span class="fragment" data-fragment-index="0">
									Let $V$ be a real inner product space.
								</span>
								<span class="fragment" data-fragment-index="1">
									A nonempty set of vectors in $V$ is <strong>orthogonal</strong> if each vector in
									the set is
									orthogonal to all the other vectors in the set.
								</span>
								<span class="fragment" data-fragment-index="2">
									That is, the set $\{\bfv_1,\ldots,\bfv_n\}\subseteq V$ is orthogonal if
									$$
									\langle\bfv_i,\bfv_j\rangle=0,\qquad i\neq j.
									$$
								</span>
								<span class="fragment" data-fragment-index="3">
									Let $S$ be a finite set of vectors in $V$ such that ${\bf 0}\notin S$.
								</span>
								<span class="fragment" data-fragment-index="4">
									Then,
								</span>
							</p>
						</div>
						<div class="fragment" data-fragment-index="4">
							<p>
								$S$ orthogonal $\Longrightarrow$ $S$ linearly
								independent.
							</p>
						</div>
					</div>
					<br/><br/>
				</section>

				<section data-auto-animate>
					<h4>11.1 Orthogonal set</h4>
					<div class="size-65">

						<div style="font-size:70%;font-weight:bold">
							<p>
								$S$ orthogonal $\Longrightarrow$ $S$ linearly
								independent.
							</p>
						</div>
						<div class="left-txt">
							<p class="fragment" data-fragment-index="0">
								Let $S = \left\{\v_1, \v_2, \ldots, \v_n\right\}$ be orthogonal
								and consider 
								\[
								k_1 \v_1 + k_2\v_2 + \cdots + k_n\v_n = \mathbf 0.
								\]
								<span class="fragment" data-fragment-index="1">
									Then for any $\v_i\in S$
								</span>
							</p>
							<table id="eqarray">
								<tr>
									<td class="fragment" data-fragment-index="1">
										$0 $

									</td>
									<td class="fragment" data-fragment-index="1">
										$=$
									</td>
									<td class="fragment" data-fragment-index="1">
										$ \langle \mathbf 0, \v_i \rangle$
										<span class="fragment" data-fragment-index="2">
											$= \langle k_1 \v_1  + \cdots + k_n\v_n, \v_i \rangle$
										</span>
									</td>
								</tr>
								<tr class="fragment" data-fragment-index="3">
									<td>
										
									</td>
									<td>
										$=$
									</td>
									<td>
										$ k_1 \langle \v_1 , \v_i \rangle + \cdots + k_n \langle  \v_n , \v_i \rangle$
									</td>
								</tr>
								<tr >
									<td>
										
									</td>
									<td class="fragment" data-fragment-index="4">
										$=$
									</td>
									<td class="fragment" data-fragment-index="4">
										$ k_i \langle \v_i , \v_i \rangle$
										<span class="fragment" data-fragment-index="5">
											&nbsp; by orthogonality.
										</span>
									</td>
								</tr>
							</table>
							<p class="fragment" data-fragment-index="6">
								Since $\mathbf 0 \notin S$, 
								<span class="fragment" data-fragment-index="7">
									we have that $\v_i\neq \mathbf 0$ and 
									so $\langle \v_i, \v_i \rangle \neq 0$
								</span>
								<span class="fragment" data-fragment-index="8">
									$\;\Ra \; k_i =0\;\; \forall i.$
								</span>
							</p>
							<p class="fragment" data-fragment-index="9">
								Therefore $\ds \left\{\v_1, \v_2, \ldots, \v_n\right\}$ is linearly independent. $\quad \blacksquare$
							</p>
						</div>
					</div>
					<br/>
				</section>

				<section data-auto-animate>
					<h4>11.1 Orthogonal set</h4>
					
					<div>
						<iframe 
						scrolling="no" 
						title="Chapter-11: Orthogonal basis" 
						data-src="https://www.geogebra.org/material/iframe/id/vajn9uvj/width/806/height/511/border/888888/sfsb/true/smb/false/stb/false/stbh/false/ai/false/asb/false/sri/true/rc/false/ld/false/sdz/true/ctl/false" 
						width="806px" height="511px" style="border:0px;" allowfullscreen=""> </iframe>
					</div>
					<br/>
				</section>

			</section>


			<section>

				<section data-auto-animate>
					<h4>11.2 Orthonormal basis</h4>
					<div class="size-70">
						<div class="left-txt">
							<p>
								<span class="fragment" data-fragment-index="0">
									An orthogonal set of vectors in $V$ is called
									<strong>orthonormal</strong> if all the vectors
									in the set are unit vectors.
								</span>
								<span class="fragment" data-fragment-index="1">
									That is, the set $\{\bfe_1,\ldots,\bfe_n\}\subset V$ is orthonormal if
									$$
									\langle\bfe_i,\bfe_j\rangle=\delta_{i,j},
									$$
								</span>
								<span class="fragment" data-fragment-index="2">
									where the <strong>Kronecker delta</strong> is defined by
									$$
									\delta_{i,j}=\begin{cases} \,0,\ & i\neq j,\\[.15cm] \,1,\ &i=j. \end{cases}
									$$
								</span>
							</p>
						</div>
					</div>
					<div class="size-70">
						<div class="left-txt">
							<p class="fragment" data-fragment-index="3">
								<span>
									Examples in $\R^n$ endowed with the
									usual dot product are given as follows:
								</span>
							</p>
						</div>
					</div>
				</section>

				<section data-auto-animate>
					<h4>11.2 Orthonormal basis</h4>
					<div class="size-70">
						<div class="left-txt">
							<p>
								<span>
									Examples in $\R^n$ endowed with the
									usual dot product are given as follows:
								</span>
							</p>
							<p class="fragment" data-fragment-index="0">
								<strong>Example 1:</strong> 
								$\left\{ (1,0,0), (0,1,0), (0,0,1)\right\}$ orthonormal set.
							</p>
							<br/>
							<p class="fragment" data-fragment-index="1">
								<strong>Example 2:</strong> 
								$\mathcal S = \left\{ 
								\left( \frac{1}{\sqrt{3}},\frac{1}{\sqrt{3}},\frac{1}{\sqrt{3}} \right), 
								\left(-\frac{1}{\sqrt{2}},\frac{1}{\sqrt{2}},0\right)
								\right\}$ orthonormal set in 
								$\R^3$.
							</p>
							<br/>
							<p class="fragment" data-fragment-index="2">
								<strong>Example 3:</strong> 
								$\mathcal S \cup  \left\{ 
									\left( \frac{1}{\sqrt{6}},\frac{1}{\sqrt{6}},-\frac{2}{\sqrt{6}} \right)
									\right\}$ orthonormal set in 
									$\R^3$.
							</p>
						</div>
					</div>
					<br/><br/>
				</section>

				<section data-auto-animate>
					<h4>11.2 Orthonormal basis</h4>
					
					<div>
						<iframe scrolling="no" title="Chapter-11: Examples orthonormal basis" 
						src="https://www.geogebra.org/material/iframe/id/temf7ugd/width/798/height/473/border/888888/sfsb/true/smb/false/stb/false/stbh/false/ai/false/asb/false/sri/true/rc/false/ld/false/sdz/true/ctl/false" 
						width="798px" height="473px" style="border:0px;"> </iframe>
					</div>
					<br/>
				</section>

				<section data-auto-animate>
					<h4>11.2 Orthonormal basis</h4>
					<div class="size-50">
						<div class="left-txt">
							<p>
								<span>
									Examples in $\R^n$ endowed with the
									usual dot product are given as follows:
								</span>
							</p>
							<p>
								<strong>Example 1:</strong> 
								$\left\{ (1,0,0), (0,1,0), (0,0,1)\right\}$ orthonormal set.
							</p>
							<p>
								<strong>Example 2:</strong> 
								$\mathcal S = \left\{ 
								\left( \frac{1}{\sqrt{3}},\frac{1}{\sqrt{3}},\frac{1}{\sqrt{3}} \right), 
								\left(-\frac{1}{\sqrt{2}},\frac{1}{\sqrt{2}},0\right)
								\right\}$ orthonormal set in 
								$\R^3$.
							</p>
							<p>
								<strong>Example 3:</strong> 
								$\mathcal S \cup  \left\{ 
									\left( \frac{1}{\sqrt{6}},\frac{1}{\sqrt{6}},-\frac{2}{\sqrt{6}} \right)
									\right\}$ orthonormal set in 
									$\R^3$.
							</p>
						</div>
					</div>
					<div class="size-70">
						<div class="left-txt">
							<p>
								<span>
									An <strong>orthonormal basis</strong> for $V$ is a basis
									for $V$ that is also an orthonormal set.
								</span>
							</p>

							<p class="fragment" data-fragment-index="0">
								The sets in Examples 1 and 3 are also orthonormal vasis for $\R^3$,
								but the set in Example 2 <strong>is  NOT</strong> a basis for $\R^3$.
							</p>
						</div>
					</div>
					<br/>
					<br/>
					
				</section>

				

			</section>

			<section>

				<section data-auto-animate>
					<h4>11.3 Decomposition theorem</h4>
					<div class="size-70">
						<div class="left-txt">
							<p>
								<span class="fragment" data-fragment-index="0">
									Let $S=\{\bfe_1,\ldots,\bfe_n\}$ be an
									orthonormal basis for $V$, and let $\bfu\in V$.
								</span>
								<span class="fragment" data-fragment-index="1">
									Then,
									$$
									\bfu=\langle\bfu,\bfe_1\rangle\bfe_1+\ldots+\langle\bfu,\bfe_n\rangle\bfe_n
									$$
								</span>
								<span class="fragment" data-fragment-index="2">
									and
									$$
									||\bfu||^2=\langle\bfu,\bfe_1\rangle^2+\ldots+\langle\bfu,\bfe_n\rangle^2.
									$$
								</span>
							</p>
						</div>
					</div>
					<br/><br/><br/><br/>
				</section>

				<section data-auto-animate>
					<h4>11.3 Decomposition theorem</h4>
					<div class="size-60">
						<div class="left-txt">
							<p>
								<span>
									<strong>
										Proof:
									</strong>
								</span>
								<span class="fragment" data-fragment-index="0">
									Since $S=\{\bfe_1,\ldots,\bfe_n\}$ is a basis
								</span>
								<span class="fragment" data-fragment-index="1">
									we can write  for any $\u\in V$
									\[
									\u = a_1\v_1 + a_1\v_1 + \cdots + a_n\v_n.
									\]
								</span>

							</p>
							<p class="fragment" data-fragment-index="2">
								Then for $i = 1, \ldots n$
							</p>
							<table id="eqarray">
								<tr class="fragment" data-fragment-index="2">
									<td>
										$\langle \u, \bfe_i \rangle$
									</td>
									<td>
										$=$
									</td>
									<td>
										$\langle a_1\bfe_1 + a_1\bfe_1 + \cdots + a_n\bfe_n, \bfe_i \rangle$
									</td>
								</tr>
								<tr class="fragment" data-fragment-index="3">
									<td>
										
									</td>
									<td>
										$=$
									</td>
									<td>
										$a_1\langle \bfe_1 , \bfe_i \rangle+ \cdots + a_n\langle \bfe_n , \bfe_i \rangle$
									</td>
								</tr>
								<tr class="fragment" data-fragment-index="4">
									<td>
										
									</td>
									<td>
										$=$
									</td>
									<td>
										$a_i\langle \bfe_i , \bfe_i \rangle$ 
										<span class="fragment" data-fragment-index="5">
											$\,=a_i. \qquad \blacksquare$
										</span>
									</td>
								</tr>
							</table>
							<p class="fragment" data-fragment-index="6">
								<strong>Note:</strong>
								$\norm{\u}^2 = \langle \u ,\u \rangle $
								<span class="fragment" data-fragment-index="7">
									$= \langle \u ,\bfe_1 \rangle ^2+ \cdots +\langle \u ,\bfe_n \rangle ^2.$
								</span>
							</p>
						</div>
					</div>
					<br/><br/>
				</section>

			</section>

			<section>

				<section data-auto-animate>
					<h4>11.4 Orthogonal projection</h4>
					<div class="size-70">
						<div class="left-txt">
							<p>
								<span class="fragment" data-fragment-index="0">
									Let $U$ be a finite-dimensional subspace
									of the real inner product space $V$.
								</span>
								<span class="fragment" data-fragment-index="1">
									Then, each $\bfv\in V$ can be written in a unique way as
									$$
									\bfv=\bfu+\bfw,\qquad \bfu\in U,\quad \bfw\in U^\bot.
									$$
								</span>
								<span class="fragment" data-fragment-index="2">
									In the proof, we will assume that $U$ has
									an orthonormal basis $S=\{\bfe_1,\ldots,\bfe_k\}$.
								</span>
								<span class="fragment" data-fragment-index="3">
									As we will see in
									Section 11.6, this assumption
									is redundant since every
									finite-dimensional inner product space <em>has</em>
									such a basis.
								</span>
							</p>
						</div>
					</div>
					<br/><br/><br/>
				</section>

				<section data-auto-animate>
					<h4>11.4 Orthogonal projection</h4>
					<div class="size-70">
						<div class="left-txt">
							<p>
								<span>
									<strong>
										Proof:
									</strong>
								</span>
								<span class="fragment" data-fragment-index="0">
									Let $\v\in S$, 
								</span>
								<span class="fragment" data-fragment-index="1">
									then $\v = \u + (\v - \u)$ for any $\u \in U.$
								</span>
								<span class="fragment" data-fragment-index="2">
									Set 
									\[
									\u = \langle \v, \bfe_1 \rangle \bfe_1 + \cdots + \langle \v, \bfe_n \rangle \bfe_n, \quad \text{then }\u \in U. \qquad (\star)
									\]
								</span>
								<span class="fragment" data-fragment-index="3">
									and set  $\w = \v-\u$. 
								</span>
								<span class="fragment" data-fragment-index="4">
									Then for $i = 1 , \ldots , \k$ we have
								</span>
							</p>
							<table id="eqarray">
								<tr class="fragment" data-fragment-index="5">
									<td>
										$\langle \w, \bfe_i \rangle$
									</td>
									<td>
										$=$
									</td>
									<td>
										$\langle \v - \langle \v, \bfe_1\rangle\bfe_1 -  \cdots - \langle \v, \bfe_k\rangle\bfe_k, \bfe_i \rangle$
									</td>
								</tr>
								<tr class="fragment" data-fragment-index="6">
									<td>
										
									</td>
									<td>
										$=$
									</td>
									<td>
										$\langle \v , \bfe_i \rangle-  \langle \v , \bfe_i \rangle  \langle \bfe_i , \bfe_i \rangle$
										
									</td>
								</tr>
								<tr class="fragment" data-fragment-index="7">
									<td>
										
									</td>
									<td>
										$=$
									</td>
									<td>
										$\langle \v , \bfe_i \rangle-  \langle \v , \bfe_i \rangle $
										<span class="fragment" data-fragment-index="8">
											$\,=0$
										</span>
									</td>
								</tr>
								
							</table>
							<p class="fragment" data-fragment-index="9">
								Then $\w$ is orthogonal to every vector in $U= \text{span} (S)$,
								<span class="fragment" data-fragment-index="10">
									which implies
									$\w\in U^{\perp}.$
								</span>
							</p>
						</div>
					</div>
					<br/>
				</section>

				<section data-auto-animate>
					<h4>11.4 Orthogonal projection</h4>
					<div class="size-70">
						<div class="left-txt">
							<p>
								<span>
									<strong>
										Proof:
									</strong>
								</span>
								<span>
									For uniqueness let $\v = \u + \w$ and $\v = \u'+ \w'$,
								</span>
								<span class="fragment" data-fragment-index="0">
									where $\u, \u'\in U$ and $\w, \w'\in U^{\perp}$.
								</span>
								<span class="fragment" data-fragment-index="1">
									Then 
									\[
									\u - \u' = \w' - \w
									\]
								</span>
								<span class="fragment" data-fragment-index="2">
									but $U \cap U^{\perp} = \{\mathbf 0\}.$
								</span>
								<span class="fragment" data-fragment-index="3">
									Then 
									\[
									\u - \u' = \mathbf 0 =  \w'- \w.
									\]
								</span>
								<span class="fragment" data-fragment-index="4">
									That is $\u = \u'$ and $\w=\w'.$
								</span>
								<span class="fragment" data-fragment-index="5">
									This implies uniqueness. $\quad \blacksquare$
								</span>
								
							</p>
							
							
						</div>
					</div>
					<br/>
				</section>

				<section data-auto-animate>
					<h4>11.4 Orthogonal projection</h4>
					<div class="size-70">
						<div class="left-txt">
							<p>
								<span>
									The vector $\bfu\in U$ is called the
									<strong>orthogonal projection of $\bfv$ onto $U$</strong>
									and is given by
									$$
									\mathrm{Proj}_U(\bfv)=\langle\bfv,\bfe_1\rangle\bfe_1+\ldots+\langle\bfv,\bfe_k\rangle\bfe_k.
									$$
								</span>
								<span class="fragment" data-fragment-index="1">
									Likewise, the vector $\bfw\in U^\bot$ is called the {\bf orthogonal projection of
									$\bfv$ onto $U^\bot$} and is given by
									$$
									\mathrm{Proj}_{U^\bot}(\bfv)=\bfv-\mathrm{Proj}_U(\bfv).
									$$
								</span>

							</p>

						</div>
					</div>
					<br/><br/>
				</section>

				<section data-auto-animate>
					<h4>11.4 Orthogonal projection</h4>
					<div class="size-70">
						<div class="left-txt">

							<p>
								One can show that
								$$
								\dim V=\dim U+\dim U^\bot.
								$$
								<span class="fragment" data-fragment-index="3">
									This can be very helpful when determining
									the orthogonal complement of a subspace $U$.
								</span>
								<span class="fragment" data-fragment-index="4">
									Indeed, suppose you have managed to find
									$\dim V-\dim U$ linearly independent
									vectors that are all orthogonal to $U$.
								</span>
								<span class="fragment" data-fragment-index="5">
									Then, these vectors will, in fact, form a basis for
									$U^\bot$. This property will be used in the next example.
								</span>
							</p>
						</div>
					</div>
					<br/><br/>
				</section>

			</section>

			<section>

				<section data-auto-animate>
					<h4>11.5 Example: Orthogonal projection in $\R^3$</h4>
					<div class="size-70">
						<div class="left-txt">
							<p>
								<span class="fragment" data-fragment-index="0">
									Let $\R^3$ be endowed with the
									usual dot product, and let
									$$
									U=
									{\rm
									span}\left(\left\{(0,1,0),\left(-\dfrac{4}{5},0,\dfrac{3}{5}\right)\right\}\right),\quad
									\bfv=(1,1,1).
									$$
								</span>
								<span class="fragment" data-fragment-index="1">
									Find the orthogonal projections of $\bfv$ onto $U$ and $U^\bot$.
								</span>
								<span class="fragment" data-fragment-index="2">
									First, consider $U = \text{span}(S)$,
								</span>
								<span class="fragment" data-fragment-index="3">
									 where $S = \left\{\bfe_1 , \bfe_2\right\}$ is the orthonormal set (Check it!📝).
								</span>
							</p>
							
						</div>
					</div>
					<br/><br/><br/>
				</section>
				<section data-auto-animate>
					<h4>11.5 Example: Orthogonal projection in $\R^3$</h4>
					<div style="font-size:35%">
						<div class="left-txt">
							<p>
								<span>
									Let $\R^3$ be endowed with the
									usual dot product, and let
									$$
									U=
									{\rm
									span}\left(\left\{(0,1,0),\left(-\dfrac{4}{5},0,\dfrac{3}{5}\right)\right\}\right),\quad
									\bfv=(1,1,1).
									$$
								</span>
								<span >
									Find the orthogonal projections of $\bfv$ onto $U$ and $U^\bot$.
								</span>
								<span>
									First, consider $U = \text{span}(S)$, where $S = \left\{\bfe_1 , \bfe_2\right\}$ is the orthonormal set (Check it!📝).
								</span>
							</p>
						</div>
					</div>
					<div class="size-60">
						<div class="left-txt">
							<p>
								<span class="fragment" data-fragment-index="0">
									Orthogonal projection onto $U$ means
								</span>
							</p>
							<table id="eqarray">
								<tr class="fragment" data-fragment-index="0">
									<td>
										$\u$
									</td>
									<td>
										$=$
									</td>
									<td>
										$\mathrm{Proj}_{U}(\v)$
										<span class="fragment" data-fragment-index="1">
											$\,=\, \langle \v, \bfe_1\rangle\bfe_1 +  \langle \v, \bfe_2\rangle\bfe_2$
										</span>
									</td>
								</tr>
								<tr class="fragment" data-fragment-index="2">
									<td>
										
									</td>
									<td class="fragment" data-fragment-index="2">
										$=$
									</td>
									<td class="fragment" data-fragment-index="2">
										$\cdots$
										<span class="fragment" data-fragment-index="2">
											$\,=\, \bfe_1 - \frac{1}{5} \bfe_2$
										</span>
										<span class="fragment" data-fragment-index="3">
											$\,=\, \ds\left(\frac{4}{25} , 1, - \frac{3}{25}\right).$
										</span>
									</td>
								</tr>
							</table>

							<p>
								<span class="fragment" data-fragment-index="5">
									Orthogonal projection onto $U^{\perp}$ means
								</span>
							</p>
							<table id="eqarray">
								<tr class="fragment" data-fragment-index="5">
									<td>
										$\w$
									</td>
									<td>
										$=$
									</td>
									<td>
										$\mathrm{Proj}_{U^{\perp}}(\v)$
										<span class="fragment" data-fragment-index="6">
											$\,=\, \v - \u$
										</span>
									</td>
								</tr>
								<tr >
									<td>
										
									</td>
									<td class="fragment" data-fragment-index="7">
										$=$
									</td>
									<td class="fragment" data-fragment-index="7">
										$\ds \left(\frac{21}{25} , 0,  \frac{28}{25}\right).$
										
									</td>
								</tr>
							</table>
							
						</div>
					</div>
					<br/>
				</section>

				

			</section>

			<section>

				<section data-auto-animate>
					<h4>11.6 Construction of orthonormal basis</h4>
					<div class="size-65">
						<div class="left-txt">
							<p>
								<span class="fragment" data-fragment-index="0">
									It is often convenient to have an
									orthonormal basis for a given
									finite-dimensional inner product space.
								</span>
								<span class="fragment" data-fragment-index="1">
									The following algorithm turns a linearly 
									independent set of vectors into an
									orthonormal set of vectors
									with the same span as the original set.
								</span>
								<span class="fragment" data-fragment-index="2">
									Applying the algorithm to a basis thus 
									turns the basis into an orthonormal basis. 
								</span>
								<span class="fragment" data-fragment-index="3">
									Hence:
								</span>
							</p>
							<div id="theorem"  class="fragment" data-fragment-index="3">
								<p style="font-size:120%">
									Every finite-dimensional real inner product space has an orthonormal basis.
								</p>
							</div>
							<p class="fragment" data-fragment-index="4">
								Let $\{\bfv_1,\ldots,\bfv_n\}$ be a 
								linearly independent set of vectors in the 
								real inner product space $V$.
								<span class="fragment" data-fragment-index="5">
									The corresponding <strong>Gram-Schmidt process</strong>
									is the following algorithm:
								</span>
							</p>
						</div>
					</div>
					<br/>
				</section>

				<section data-auto-animate>
					<h4>11.6 Construction of orthonormal basis</h4>
					
					<div class="size-60">
						<div class="left-txt">
							<p style="font-size:80%">
								<span>
									The corresponding <strong>Gram-Schmidt process</strong>
									is the following algorithm:
								</span>
							</p>
							<p class="fragment" data-fragment-index="0">
								<strong>
									Step 1:
								</strong>
								Let $\w_1 = \v_1$. 
								<span class="fragment" data-fragment-index="1">
									(Easy! 😃)
								</span>
							</p>
							<p class="fragment" data-fragment-index="2">
								<strong>
									Step 2: 
								</strong>
								We can obtain a vector $\w_2$ that is 
								orthogonal to $\w_1$ by computing the 
								component of $\v_2$ that is 
								orthogonal to the space $W_1$ spanned
								by $\w_1$. 
								<span class="fragment" data-fragment-index="3">
									To do this we use the formula:
								\[
								\w_2 = \v_2 - \mathrm{Proj}_{W_1} \v_2 = \v_2 - \frac{\langle \v_2, \w_1 \rangle}{\norm{w_1}^2}\w_1.
								\]
								</span>
							</p>
							<p class="fragment" data-fragment-index="4">
								<strong>
									Step 3:
								</strong>
								To construct a vector $\w_3$ that is orthogonal 
								to both $\w_1$ and $\w_2$, we compute the 
								component of $v_3$ orthogonal to the 
								space $W_3$ spanned by $w_1$ and $w_2$. 
								<span class="fragment" data-fragment-index="5">
									Here we use the 
								formula:
								\[
								\w_3 = \v_3 - \mathrm{Proj}_{W_2} \v_3 = \v_3 - \frac{\langle \v_3, \w_1 \rangle}{\norm{w_1}^2}\w_1 -  \frac{\langle \v_3, \w_2 \rangle}{\norm{w_2}^2}\w_2.
								\]
								</span>
							</p>
						</div>
					</div>
					<br/>
				</section>

				<section data-auto-animate>
					<h4 style="font-size:70%">11.6 Construction of orthonormal basis</h4>
					
					<div class="size-55">
						<div class="left-txt">
							
							<p>
								<strong>
									Step 1:
								</strong>
								Let $\w_1 = \v_1$. 
								<span>
									(Easy! 😃)
								</span>
							</p>
							<p>
								<strong>
									Step 2: 
								</strong>
								We can obtain a vector $\w_2$ that is 
								orthogonal to $\w_1$ by computing the 
								component of $\v_2$ that is 
								orthogonal to the space $W_1$ spanned
								by $\w_1$. To do this we use the formula:
								\[
								\w_2 = \v_2 - \mathrm{Proj}_{W_1} \v_2 = \v_2 - \frac{\langle \v_2, \w_1 \rangle}{\norm{w_1}^2}\w_1.
								\]
							</p>
							<p>
								<strong>
									Step 3:
								</strong>
								To construct a vector $\w_3$ that is orthogonal 
								to both $\w_1$ and $\w_2$, we compute the 
								component of $v_3$ orthogonal to the 
								space $W_3$ spanned by $w_1$ and $w_2$. Here we use the 
								formula:
								\[
								\w_3 = \v_3 - \mathrm{Proj}_{W_2} \v_3 = \v_3 - \frac{\langle \v_3, \w_1 \rangle}{\norm{w_1}^2}\w_1 -  \frac{\langle \v_3, \w_2 \rangle}{\norm{w_2}^2}\w_2.
								\]
							</p>
							<p class="fragment" data-fragment-index="0">
								<strong>
									$n$ step:
								</strong>
								Continuing in this way we will produce after
								$n$ steps an orthogonal set of nonzero
								vectors $\left\{\w_1, \w_2, \ldots,  \w_n \right\}.$
							</p>
							<p class="fragment" data-fragment-index="1">
								<strong>
									Final step:
								</strong>
								To convert the orthogonal basis into an orthonormal basis
								$\left\{\mathbf q_1, \mathbf q_2, \ldots,  \mathbf q_n \right\},$ 
								normalize the orthogonal basis vectors.
							</p>
						</div>
					</div>
					<br/>
				</section>

				<section data-auto-animate>
					<h4>
						<h4>11.6 Construction of orthonormal basis</h4>
					</h4>
					<img width="480px" data-src="images/chapter-11/Gram-Schmidt_orthonormalization_process.gif">

					<p style="font-size:16px"><strong>Author:</strong> 
						<a href="https://1ucasvb.tumblr.com/" target="_blank">Lucas Vieira</a> -
						<a href="https://twitter.com/LucasVB" target="_blank">@LucasVB</a>
						
					</p>
					<br/>
				</section>
 
			</section>

			<section>
				<h4>11.7 Example: Orthonormal basis for $P_1(\R)$</h4>
				<div class="left-txt size-80 fragment" data-fragment-index="0">
					<p>
						<strong>Exercise:</strong> 📝 Here the inner product is 
						\[
						\langle \mathbf p, \mathbf q \rangle= \int_{-1}^{1}p(x)q(x)dx
						\]
						and the basis is $\beta = \left\{1+ x, 1-2x\right\}$.
					</p>
				</div>
				<br/><br/><br/><br/>
			</section>


			<section>

				<h4>Credits</h4>
				<div include-html="creditsb.html"></div>
			</section>

			<!-- Ends sections -->

		</div>
	</div>

	<script src="dist/reveal.js"></script>
	<script src="plugin/math/math.js"></script>
	<script src="plugin/highlight/highlight.js"></script>
	<script src="plugin/chalkboard/plugin.js"></script>
	<script src="plugin/customcontrols/plugin.js"></script>
	<script src="plugin/menu/menu.js"></script>
	<script src="mySetup/setup.js"></script>

	<script>
		includeHTML();
	</script>


</body>

</html>